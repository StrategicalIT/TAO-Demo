- hosts: master
  gather_facts: yes
  vars_files:
    - cns_values.yaml
  tasks:
  
   - name: Get Nvidia Tegra Release
     shell: uname -r | awk -F'-' '{print $2}'
     register: release

   - set_fact:
       release: "{{ release.stdout }}"

   - name: Uninstall the GPU Operator with MIG
     ignore_errors: true
     shell: |
       kubectl label nodes --all nvidia.com/mig.config=all-disabled --overwrite
       sleep 5
       config_state=$(kubectl describe nodes  |grep mig.config.state |head -n1 | awk -F'=' '{print $2}')
       while [ $config_state != "success" ]
       do
         sleep 5
         config_state=$(kubectl describe nodes  |grep mig.config.state | head -n1 |awk -F'=' '{print $2}')
       done
     when: "enable_mig == true and cns_version >= 4.1 and release != 'tegra'"
     #failed_when: false
     async: 120
     args:
       executable: /bin/bash

   - name: Uninstall Helm Charts on NVIDIA Cloud Native Stack
     ignore_errors: true
     when:  release != 'tegra'
     async: 120
     shell: |
       count=$(helm ls -A | egrep 'gpu-operator|network-operator' | grep -v NAME | wc -l)
       if [[ $count > 0 ]]; then
        for name in `helm ls -A | awk '{print $1}' | grep -v NAME`
        do
          for namespace in `helm ls -A | grep $name |  awk '{print $2}' | grep -v NAMESPACE`
            do
              helm del $name -n $namespace --wait
              pods=$(kubectl get pods -n $namespace | grep -v NAME | wc -l)
              while [ $pods != 0 ]
              do
                sleep 10
                pods=$(kubectl get pods -n $namespace | grep -v NAME | wc -l)
              done
            done
        done
       fi
     args:
      executable: /bin/bash
      
- hosts: all
  gather_facts: yes
  become: true
  vars_files:
    - cns_values.yaml
  tasks:

   - name: Reset Kubernetes component
     when: container_runtime == 'cri-o'
     shell: "timeout 45 kubeadm reset --cri-socket=unix:///var/run/crio/crio.sock --force"
     failed_when: false
     no_log: True

   - name: Reset Kubernetes component
     when: container_runtime == 'cri-dockerd'
     shell: "timeout 45 kubeadm reset --cri-socket=unix:///run/cri-dockerd.sock --force"
     failed_when: false
     no_log: True

   - name: Reset Kubernetes component
     when: container_runtime == 'containerd'
     shell: "timeout 45 kubeadm reset --cri-socket=unix///run/containerd/containerd.sock --force"
     failed_when: false
     no_log: True

   - name: IPTables Cleanup
     ignore_errors: yes
     failed_when: false
     become: true
     shell: "{{ item }}"
     with_items: 
       - iptables -F
       - ip link delete cni0
       - ip link delete flannel.1

   - name: Check docker is installed
     shell: /usr/bin/docker
     register: docker_exists
     no_log: true
     failed_when: false
     args:
      executable: /bin/bash

   - name: Remove all docker images and cache
     when: "cns_docker == true and docker_exists.rc == 0 or container_runtime == 'cri-dockerd' and docker_exists.rc == 0"
     ignore_errors: yes
     failed_when: false
     no_log: True
     async: 120
     shell: "{{ item }}"
     with_items:
       - docker system prune -a --volumes
       - docker rm -vf $(docker ps -aq)
       - docker prune --all

   - name: Stopping and disable the required services
     become: true
     service:
       name: "{{ item }}"
       state: stopped
       enabled: false
       daemon_reload: yes
     failed_when: false
     with_items:
       - docker
       - kubelet
       - containerd
       - crio
       - cri-o
       - cri-docker

   - name: Remove Kubernetes packages for Ubuntu
     when: "ansible_distribution == 'Ubuntu' and cns_version >= 4.0"
     ignore_errors: yes
     apt:
       name: "{{ item }}"
       state: absent
       purge: yes
       force: yes
       autoremove: yes
       allow_change_held_packages: true
     loop:
       - kubeadm
       - kubelet
       - kubectl

   - name: Remove CRI-O packages for Ubuntu
     when: "ansible_distribution == 'Ubuntu' and cns_version >= 4.0 and container_runtime == 'cri-o'"
     ignore_errors: yes
     apt:
       name: "{{ item }}"
       state: absent
       purge: yes
       force: yes
       autoremove: yes
       allow_change_held_packages: true
     loop:
       - cri-o*
       - cri-o-runc*

   - name: Remove Docker and Kubernetes packages for Ubuntu
     when: "cns_docker == true and ansible_distribution == 'Ubuntu' or cns_version <= 3.1 and ansible_distribution == 'Ubuntu'"
     ignore_errors: yes
     apt:
       name: "{{ item }}"
       state: absent
       purge: yes
       force: yes
       autoremove: yes
       allow_change_held_packages: true
     loop:
       - kubeadm
       - kubelet
       - kubectl
       - docker*
       - docker-ce*
       - containerd*
       - nvidia-docker*

   - name: Remove NVIDIA Docker for Cloud Native Stack Developers on Ubuntu
     when: "cns_docker == true and ansible_distribution == 'Ubuntu' or cns_nvidia_driver == true and ansible_distribution == 'Ubuntu'"
     ignore_errors: yes
     apt:
       name: "{{ item }}"
       state: absent
       purge: yes
       force: yes
       autoremove: yes
       allow_change_held_packages: true
     loop:
       - cuda-drivers
       - nvidia-driver-*
       - nvidia-dkms-*
       - nvidia-utils-*
       - cuda
       - nvidia-container*

   - name: Remove NVIDIA Docker for Cloud Native Stack Developers on Redhat
     when: "cns_docker == true and ansible_distribution == 'RedHat' or cns_nvidia_driver == true and ansible_distribution == 'RedHat'"
     ignore_errors: yes
     yum:
       name: "{{ item }}"
       state: absent
     loop:
       - '@nvidia-driver:525-dkms'
       - '@nvidia-driver:535-dkms'
       - 'nvidia-container*'
       - 'nvidia-docker*'

   - name: Uninstall NVIDIA TRD Driver 
     when: cns_nvidia_driver == true
     shell: "sh ./NVIDIA-Linux-{{ ansible_architecture }}-{{ gpu_driver_version }}.run --uninstall --silent; rm -rf ./NVIDIA-Linux-{{ ansible_architecture }}-{{ gpu_driver_version }}.run"
     become: true
     ignore_errors: true

   - name: Remove dependencies that are no longer required
     when: "ansible_distribution == 'Ubuntu'"
     apt:
      autoremove: yes

   - name: Remove dependencies that are no longer required
     when: "ansible_distribution == 'RedHat'"
     yum:
      autoremove: yes

   - name: Remove installed packages for RHEL/CentOS
     when:  "ansible_distribution in ['RedHat', 'CentOS']"
     ignore_errors: yes
     yum:
       name: "{{ item }}"
       state: absent
     loop:
       - kubectl
       - kubeadm
       - kubelet
       - docker*
       - cri*

   - name: Cleanup Containerd Process
     shell: kill -9 $( ps -ef|grep containerd | awk '{print $2}')
     no_log: true
     failed_when: false
     ignore_errors: yes

   - name: NVIDIA FS Module Cleanup
     ignore_errors: yes
     failed_when: false
     become: true
     shell: rmmod nvidia_fs

   - name: Cleanup Directories for Cloud Native Stack Developers
     when: " cns_docker == true and cns_nvidia_driver == true or cns_version <= 3.1 or container_runtime == 'cri-dockerd'"
     ignore_errors: yes
     file:
       path: "{{ item }}"
       state: absent
     with_items:
        - /etc/docker
        - /var/lib/docker
        - /var/run/docker
        - /run/docker.sock
        - /run/docker
        - /usr/lib/nvidia
        - /usr/local/nvidia
        - /run/nvidia
        - /etc/apt/sources.list.d/nvidia-docker
        - /etc/apt/sources.list.d/docker

   - name: Cleanup Directories
     ignore_errors: yes
     shell: rm -rf "{{ item }}"
     with_items:
#        - /var/lib/containerd
#        - /run/containerd
#        - /opt/containerd
        - /etc/containerd
        - /var/run/docker.pid
        - /usr/local/sbin/runc
        - /usr/local/bin/crictl
        - /etc/crictl.yaml
        - /usr/local/bin/containerd
        - /usr/local/bin/containerd-s*
        - /var/lib/etcd
        - /var/lib/containerd
        - /etc/kubernetes
        - /etc/apt/sources.list.d/kubernetes.list
        - /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list
        - /etc/apt/sources.list.d/devel:kubic:libcontainers:stable:cri-o:{{ k8s_version }}.list
        - /etc/apt/sources.list.d/libnvidia-container.list
        - /etc/apt/sources.list.d/nvidia-container-toolkit.list
        - /usr/local/bin/helm
        - /var/lib/crio
        - /etc/crio
        - /usr/local/bin/crio
        - /var/log/containers
        - /etc/apt/sources.list.d/devel*
        - /etc/sysctl.d/99-kubernetes-cri.conf
        - /etc/modules-load.d/containerd.conf
        - /etc/modules-load.d/crio.conf
        - /etc/apt/trusted.gpg.d/libcontainers*
        - /etc/default/kubelet
        - /etc/cni/net.d
        - /etc/systemd/system/containerd.service.d/http-proxy.conf
        - /var/log/pods
        - /opt/local-path-provisioner
        - /usr/local/bin/cri-dockerd
        - /etc/systemd/system/cri-docker.service
        - /etc/systemd/system/cri-docker.socket
        - /etc/apt/sources.list.d/libnvidia-container.list
        - /etc/apt/sources.list.d/nvidia-container-toolkit.list

   - name: Reboot the system
     when: "cns_docker == true or cns_nvidia_driver == true"
     reboot:
       reboot_timeout: 900