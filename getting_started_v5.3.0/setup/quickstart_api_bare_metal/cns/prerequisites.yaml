- hosts: all
  gather_facts: true
  vars_files:
    - cns_values.yaml
  environment:
    http_proxy: "{{ http_proxy }}"
    https_proxy: "{{ https_proxy }}"
  tasks:
    - name: Get Nvidia Tegra Release
      shell: uname -r | awk -F'-' '{print $2}'
      register: release

    - set_fact:
       release: "{{ release.stdout }}"

    - name: Validate whether Kubernetes cluster installed
      shell: kubectl cluster-info
      register: k8sup
      no_log: True
      failed_when: false

    - name: Create a APT KeyRing directory
      become: true
      when: "ansible_distribution == 'Ubuntu' and ansible_distribution_major_version <= '20' and 'running' not in k8sup.stdout"
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Add an Kubernetes apt signing key for Ubuntu
      become: true
      when: "ansible_distribution == 'Ubuntu' and 'running' not in k8sup.stdout"
      apt_key:
        url: "{{ k8s_apt_key }}"
        keyring: "{{ k8s_apt_ring }}"
        state: present

    - name: change apt repo
      shell: "echo {{ k8s_apt_key }} | rev  | cut -c12- | rev"
      register: k8s_apt_repository

    - name: change gpg repo
      shell: "echo {{ k8s_gpg_key }} | rev  | cut -c24- | rev"
      register: k8s_gpg_repository

    - name: Adding Kubernetes apt repository for Ubuntu
      become: true
      when: "ansible_distribution == 'Ubuntu' and 'running' not in k8sup.stdout"
      apt_repository:
        repo: "deb [signed-by={{ k8s_apt_ring }}] {{ k8s_apt_repository.stdout }} /"
        state: present
        filename: kubernetes

    - name: Add Kubernetes repo for RHEL
      become: true
      when: "ansible_distribution == 'RedHat' and 'running' not in k8sup.stdout"
      yum_repository:
        name: kubernetes
        description: Kubernetes repo
        baseurl: "{{ k8s_gpg_repository.stdout }}"
        gpgkey: "{{ k8s_gpg_key }}"
        gpgcheck: yes
        enabled: yes
        repo_gpgcheck: yes        

    - name: Install Kubernetes components for Ubuntu on NVIDIA Cloud Native Stack
      become: true
      when: "ansible_distribution == 'Ubuntu'"
      apt:
        name: ['net-tools', 'libseccomp2', 'apt-transport-https', 'curl', 'ca-certificates', 'gnupg-agent' ,'software-properties-common', 'kubelet={{ k8s_version }}-1.1', 'kubeadm={{ k8s_version }}-1.1', 'kubectl={{ k8s_version }}-1.1']
        state: present
        update_cache: true
        allow_change_held_packages: yes
        force: yes

    - name: Install Kubernetes components for RedHat on NVIDIA Cloud Native Stack
      become: true
      when: "ansible_distribution == 'RedHat'"
      yum:
        name: ['net-tools', 'libseccomp', 'curl', 'ca-certificates', 'kubelet-{{ k8s_version }}', 'kubeadm-{{ k8s_version }}', 'kubectl-{{ k8s_version }}']
        state: present

    - name: Hold the installed Packages
      become: true
      when: "ansible_distribution == 'Ubuntu'"
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      with_items:
        - kubelet
        - kubectl
        - kubeadm

    - name: Validate whether Kubernetes cluster installed
      shell: kubectl cluster-info
      register: k8sup
      no_log: True
      failed_when: false

    - name: Remove swapfile from /etc/fstab
      become: true
      when: "'running' not in k8sup.stdout"
      mount:
        name: "{{ item }}"
        fstype: swap
        state: absent
      with_items:
        - swap
        - none

    - name: Disable swap
      become: true
      when: "'running' not in k8sup.stdout"
      command: swapoff -a

    - name: disable Firewall
      become: true
      when: "'running' not in k8sup.stdout and ansible_distribution == 'RedHat'"
      service:
        state: stopped
        name: firewalld

#    - name: Firewall Rules
#      become: true
#     when: "'running' not in k8sup.stdout and ansible_distribution == 'RedHat'"
#     firewalld:
#       permanent: yes
#        immediate: yes
#        port: "{{item.port}}/{{item.proto}}"
#        state: "{{item.state}}"
#      with_items:
#       - {port: "6443", proto: "tcp", state: "enabled"}
#       - {port: "2379-2380", proto: "tcp", state: "enabled"}
#       - {port: "10230-10260", proto: "tcp", state: "enabled"}
#       - {port: "30000-32767", proto: "tcp", state: "enabled"}

    - name: Setup kernel modules for container runtime
      become: true
      block:
        - name: Create Kubernetes.conf
          lineinfile:
            create: yes
            mode: 666
            path: /etc/modules-load.d/kubernetes.conf
            line: "{{ item }}"
          loop:
            - "overlay"
            - "br_netfilter"

        - name: Modprobe for overlay and br_netfilter
          modprobe:
            name: "{{ item }}"
            state: present
          ignore_errors: true
          loop:
          - "overlay"
          - "br_netfilter"

        - name: Add sysctl parameters to /etc/sysctl.conf
          sysctl:
            name: "{{ item.name }}"
            value: "{{ item.value }}"
            state: present
            reload: "{{ item.reload }}"
          loop:
            - {name: "net.bridge.bridge-nf-call-ip6tables", value: "1", reload: no}
            - {name: "net.bridge.bridge-nf-call-iptables", value: "1", reload: no}
            - {name: "net.ipv4.ip_forward", value: "1", reload: yes}
      when: "cns_version >= 4.0"

    - name: Setup Containerd for Ubuntu
      become: true
      lineinfile:
        line: KUBELET_EXTRA_ARGS=--cgroup-driver=systemd --container-runtime=remote --container-runtime-endpoint="unix:/run/containerd/containerd.sock"
        path: /etc/default/kubelet
        create: yes
      when: "cns_version < 10.0 and container_runtime == 'containerd'"

    - name: Setup Kubelet Parameters
      become: true
      lineinfile:
        line: KUBELET_EXTRA_ARGS=--serialize-image-pulls=true"
        path: /etc/default/kubelet
        create: yes
      when: "cns_version >= 10.0"

    - name: Install Containerd for NVIDIA Cloud Native Stack
      become: true
      block:
        - name: Download cri-containerd-cni
          get_url:
            url: https://github.com/containerd/containerd/releases/download/v{{ containerd_version }}/cri-containerd-cni-{{ containerd_version }}-linux-amd64.tar.gz
            dest: /tmp/cri-containerd-cni-{{ containerd_version }}-linux-amd64.tar.gz
            mode: 0664

        - name: Untar cri-containerd-cni
          unarchive:
            src: /tmp/cri-containerd-cni-{{ containerd_version }}-linux-amd64.tar.gz
            dest: /
            remote_src: yes
            extra_opts:
              - --no-overwrite-dir

        - name: Remove Containerd tar
          file:
            path:  /tmp/cri-containerd-cni-{{ containerd_version }}-linux-amd64.tar.gz
            state: absent
      when: "ansible_system == 'Linux' and ansible_architecture == 'x86_64'"

    - name: Install Containerd for NVIDIA Cloud Native Stack
      become: true
      block:
        - name: Download cri-containerd-cni
          get_url:
            url: https://github.com/containerd/containerd/releases/download/v{{ containerd_version }}/cri-containerd-cni-{{ containerd_version }}-linux-arm64.tar.gz
            dest: /tmp/cri-containerd-cni-{{ containerd_version }}-linux-arm64.tar.gz
            mode: 0664

        - name: Untar cri-containerd-cni
          unarchive:
            src: /tmp/cri-containerd-cni-{{ containerd_version }}-linux-arm64.tar.gz
            dest: /
            remote_src: yes
            extra_opts:
              - --no-overwrite-dir

        - name: Remove Containerd tar
          file:
            path:  /tmp/cri-containerd-cni-{{ containerd_version }}-linux-arm64.tar.gz
            state: absent
      when: "ansible_system == 'Linux' and ansible_architecture == 'aarch64'"

    - name: Configure Containerd for NVIDIA Cloud Native Stack
      become: true
      block:
        - name: Create /etc/containerd
          file:
            path: /etc/containerd
            state: directory

        - name: Get defaults from containerd
          shell: /usr/local/bin/containerd config default > /etc/containerd/config.toml
          changed_when: false
          register: containerd_config_default

        - name: Enable systemd cgroups
          shell: sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml; sed -i 's/    max_concurrent_downloads = 3/    max_concurrent_downloads = {{ containerd_max_concurrent_downloads}}/g' /etc/containerd/config.toml

        - name: restart containerd
          service:
            name: containerd
            state: restarted
            daemon_reload: yes
      when: "cns_version >= 4.1 and ansible_system == 'Linux' and container_runtime == 'containerd'"

    - name: Add Containerd Proxy configuration
      become: true
      block:
        - name: Get Host IP
          shell: interface=$(ip a | grep 'state UP' |  egrep 'enp*|ens*|eno*|enc*|eth*|bond*|wlan*' | awk '{print $2}' | sed 's/://g'); for i in $interface; do ifconfig $i | grep -iw inet | awk '{print $2}'; done
          register: network

        - name: subnet
          shell: echo {{ network.stdout_lines[0] }} | cut -d. -f1-3
          register: subnet

        - name: Create containerd.service.d
          file:
            path: /etc/systemd/system/containerd.service.d
            state: directory
            recurse: yes

        - name: create http-proxy.conf
          lineinfile:
            create: yes
            mode: 666
            path: /etc/systemd/system/containerd.service.d/http-proxy.conf
            line: "{{ item }}"
          loop:
          - "[Service]"
          - "Environment='NO_PROXY={{ network.stdout_lines[0] }},localhost,127.0.0.0/8,10.96.0.1/24,10.244.0.0/16,192.168.32.0/22,{{ subnet.stdout }}.0/24'"
          - "Environment='HTTPS_PROXY={{ https_proxy }}'"
          - "Environment='HTTP_PROXY={{ http_proxy }}'"

        - name: restart containerd
          service:
            name: containerd
            state: restarted
            daemon_reload: yes
      when: "proxy == true and cns_version >= 6.1 and container_runtime == 'containerd'"

    - name: Install CRI-O on Ubuntu 22.04
      when: "container_runtime == 'cri-o' and ansible_distribution == 'Ubuntu' and ansible_distribution_major_version == '22'"
      become: true
      block:
        - name: trim CRI-O version
          shell: echo {{ crio_version }} | awk -F'.' '{print $1"."$2}'
          register: cri_version

        - name: set version
          set_fact:
            version: "{{ cri_version.stdout }}"

        - name: Adding CRI-O apt key
          apt_key:
            url: "https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/x{{ ansible_distribution }}_22.04/Release.key"
            state: present

        - name: Adding CRI-O apt key
          apt_key:
            url: "https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/x{{ ansible_distribution }}_22.04/Release.key"
            state: present

        - name: copy the apt keys
          shell: "{{ item }}"
          with_items:
            - cp /etc/apt/trusted.gpg /etc/apt/trusted.gpg.d

        - name: Add CRIO repository
          apt_repository:
            repo: "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/x{{ ansible_distribution }}_22.04 /"
            state: present
            filename: devel:kubic:libcontainers:stable

        - name: Add CRIO repository
          apt_repository:
            repo: "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/x{{ ansible_distribution }}_22.04 /"
            state: present
            filename: devel:kubic:libcontainers:stable:cri-o:{{ k8s_version }}

    - name: Install CRI-O on Ubuntu 20.04
      when: "container_runtime == 'cri-o' and ansible_distribution == 'Ubuntu' and ansible_distribution_major_version <= '20'"
      become: true
      block:
        - name: trim CRI-O version
          shell: echo {{ crio_version }} | awk -F'.' '{print $1"."$2}'
          register: cri_version

        - name: set version
          set_fact:
            version: "{{ cri_version.stdout }}"

        - name: Adding CRI-O apt key
          apt_key:
            url: "https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/x{{ ansible_distribution }}_20.04/Release.key"
            state: present

        - name: Adding CRI-O apt key
          apt_key:
            url: "https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/x{{ ansible_distribution }}_20.04/Release.key"
            state: present

        - name: copy the apt keys
          shell: "{{ item }}"
          with_items:
            - cp /etc/apt/trusted.gpg /etc/apt/trusted.gpg.d

        - name: Add CRIO repository
          apt_repository:
            repo: "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/x{{ ansible_distribution }}_20.04 /"
            state: present
            filename: devel:kubic:libcontainers:stable

        - name: Add CRIO repository
          apt_repository:
            repo: "deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/x{{ ansible_distribution }}_20.04 /"
            state: present
            filename: devel:kubic:libcontainers:stable:cri-o:{{ k8s_version }}

    - name: Install CRI-O on Ubuntu
      when: "container_runtime == 'cri-o' and ansible_distribution == 'Ubuntu' and cns_version < 10.0 "
      become: true
      block:
        - name: Setup CRI-O for Ubuntu
          become: true
          lineinfile:
            line: KUBELET_EXTRA_ARGS=--cgroup-driver=systemd --container-runtime=remote --container-runtime-endpoint="unix:///var/run/crio/crio.sock"
            path: /etc/default/kubelet
            create: yes

    - name: Install CRI-O on Ubuntu
      when: "container_runtime == 'cri-o' and ansible_distribution == 'Ubuntu'"
      become: true
      block:
        - name: install CRI-O
          apt:
            name: ['cri-o', 'cri-o-runc']
            state: present
            update_cache: true
            allow_change_held_packages: yes
            force: yes

        - name: Create overlay-images directory
          file:
            path: /var/lib/containers/storage/overlay-images
            state: directory

        - name: Update crio.conf
          blockinfile:
            path: /etc/crio/crio.conf
            block: |
              hooks_dir = [
                    "/usr/share/containers/oci/hooks.d",
              ]

    - name: Install CRI-O on RHEL
      when: "container_runtime == 'cri-o' and ansible_distribution == 'RedHat'"
      become: true
      block:
        - name: trim CRI-O version
          shell: echo {{ crio_version }} | awk -F'.' '{print $1"."$2}'
          register: cri_version

        - name: set version
          set_fact:
            version: "{{ cri_version.stdout }}"

        - name: Add CRIO repository
          yum_repository:
            name: devel:kubic:libcontainers:stable:cri-o:{{ version }}
            baseurl: https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/CentOS_8/
            gpgcheck: 1
            gpgkey: https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable:/cri-o:/{{ version }}/CentOS_8/repodata/repomd.xml.key
            enabled: 1
            description: CRIO Repo

        - name: Add CRIO repository
          yum_repository:
            baseurl: https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_8/
            gpgcheck: 1
            gpgkey: https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/CentOS_8/repodata/repomd.xml.key
            enabled: 1
            name: devel:kubic:libcontainers:stable
            description: CRIO Repo

        - name: install CRI-O
          yum:
            name: ['cri-o', 'cri-tools']
            state: present

    - name: Enable OCI hook for CRI-O
      when: cns_docker == true and container_runtime == 'cri-o'
      become: true
      copy:
        dest: /usr/share/containers/oci/hooks.d/oci-nvidia-hook.json
        content: |
          {
              "version": "1.0.0",
              "hook": {
                  "path": "/usr/bin/nvidia-container-runtime-hook",
                  "args": ["nvidia-container-runtime-hook", "prestart"],
                  "env": [
                      "PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
                  ]
              },
              "when": {
                  "always": true,
                  "commands": [".*"]
              },
              "stages": ["prestart"]
          }

    - name: Check if Docker is installed
      shell: docker
      register: docker_exists
      no_log: true
      failed_when: false

    - name: Install Docker Dependencies on Ubuntu
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'Ubuntu'
      ansible.builtin.apt:
        name:
          - apt-transport-https
          - ca-certificates
          - lsb-release
          - gnupg
          - apt-utils
          - unzip
        state: latest
        update_cache: true
 
    - name: Install Docker Dependencies on RHEL
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'RedHat'
      yum:
        name:
          - yum-utils
          - device-mapper-persistent-data
          - lvm2
          - unzip
        state: latest

    - name: Add Docker APT signing key
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'Ubuntu'
      ansible.builtin.apt_key:
        url: "https://download.docker.com/linux/{{ ansible_distribution | lower }}/gpg"
        state: present

    - name: Add Docker repository into sources list
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'Ubuntu'
      ansible.builtin.apt_repository:
        repo: "deb https://download.docker.com/linux/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
        state: present
        filename: docker

    - name: Add Docker repo on RHEL
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'RedHat'
      get_url:
        url: https://download.docker.com/linux/centos/docker-ce.repo
        dest: /etc/yum.repos.d/docer-ce.repo

    - name: Get CRI Dockerd
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_system == 'Linux' and ansible_architecture == 'x86_64'
      unarchive:
        src: https://github.com/Mirantis/cri-dockerd/releases/download/v{{ cri_dockerd_version }}/cri-dockerd-{{ cri_dockerd_version }}.amd64.tgz
        dest: /usr/local/bin/
        remote_src: yes
        mode: 0777
        extra_opts: [--strip-components=1]

    - name: Get CRI Dockerd
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_system == 'Linux' and ansible_architecture == 'aarch64'
      unarchive:
        src: https://github.com/Mirantis/cri-dockerd/releases/download/v{{ cri_dockerd_version }}/cri-dockerd-{{ cri_dockerd_version }}.arm64.tgz
        dest: /usr/local/bin/
        remote_src: yes
        mode: 0777
        extra_opts: [--strip-components=1]

    - name: Get CRI DockerD Service
      become: true
      when: container_runtime == 'cri-dockerd'
      get_url:
        url: https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.service
        dest: /etc/systemd/system/

    - name: Get CRI DockerD Service
      become: true
      when: container_runtime == 'cri-dockerd'
      get_url:
        url: https://raw.githubusercontent.com/Mirantis/cri-dockerd/master/packaging/systemd/cri-docker.socket
        dest: /etc/systemd/system/

    - name: Update CRI Dockerd
      become: true
      shell: "sed -i -e 's,/usr/bin/cri-dockerd,/usr/local/bin/cri-dockerd,' /etc/systemd/system/cri-docker.service"
      when: container_runtime == 'cri-dockerd'

    - name: Install Docker on Ubuntu
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'Ubuntu'
      package:
        name: ['docker-ce', 'docker-ce-cli', 'containerd.io']
        state: latest

    - name: Install Docker on RHEL
      become: true
      when: container_runtime == 'cri-dockerd' and ansible_distribution == 'RedHat'
      yum:
        name: ['docker-ce', 'docker-ce-cli', 'containerd.io']
        state: latest
        allowerasing: true

    - name: Update Docker service
      when: container_runtime == 'cri-dockerd'
      shell: sed -i 's/\/usr\/bin\/dockerd/\/usr\/bin\/dockerd -H unix:\/\/\/var\/run\/docker.sock/g' /lib/systemd/system/docker.service; systemctl daemon-reload; systemctl restart docker
      become: true
      ignore_errors: true

## For Jetson Only
    - name: get current JetPack version
      shell: cat /etc/nv_tegra_release | awk '{print $5}' | sed 's/,//g'
      when: release == 'tegra'
      register: jversion

    - name: get Current Tegra release
      shell: "cat /etc/apt/sources.list.d/nvidia-l4t-apt-source.list | awk '{print $3}' | tail -1f"
      register: tver

    - name: Installing Latest Nvidia Jetson JetPack
      become: true
      block:
        - name: update Tegra Release to r35.4
          shell: sed -i "s/{{ tver.stdout }}/r35.4/g" /etc/apt/sources.list.d/nvidia-l4t-apt-source.list
          become: true
          
        - name: Install New Jetapck 5.1.2
          ignore_errors: yes
          apt:
            name: nvidia-jetpack
            state: present
            force: yes
            autoremove: yes
            update_cache: yes
      when: "release == 'tegra' and cns_version == 10.2 or release == 'tegra' and cns_version == 9.3 or release == 'tegra' and cns_version == 8.5"

    - name: Installing Latest Nvidia Jetson JetPack
      become: true
      block:
        - name: get Current Tegra release
          shell: "cat /etc/apt/sources.list.d/nvidia-l4t-apt-source.list | awk '{print $3}' | tail -1f"
          register: tver

        - name: update Tegra Release to r35.3
          shell: sed -i "s/{{ tver.stdout }}/r35.3/g" /etc/apt/sources.list.d/nvidia-l4t-apt-source.list
          become: true

        - name: Install New Jetapck 5.1.1
          ignore_errors: yes
          apt:
            name: nvidia-jetpack
            state: present
            force: yes
            autoremove: yes
            update_cache: yes
      when: "release == 'tegra' and cns_version <= 10.1 and jversion.stdout < '3.1' or release == 'tegra' and cns_version <= 9.2 and jversion.stdout < '3.1' or release == 'tegra' and cns_version <= 8.4 and jversion.stdout < '3.1'"

    - name: Configure Containerd for NVIDIA Cloud Native Stack
      become: true
      block:
        - name: Create /etc/containerd
          file:
            path: /etc/containerd
            state: directory
            
        - name: Write defaults to config.toml
          copy:
            src: "{{lookup('pipe', 'pwd')}}/files/config.toml"
            dest: /etc/containerd/config.toml
            mode: 0664

        - name: Enable systemd cgroups
          shell: sed -i 's/SystemdCgroup \= false/SystemdCgroup \= true/g' /etc/containerd/config.toml

        - name: restart containerd
          service:
            name: containerd
            state: restarted
            daemon_reload: yes
      when: "cns_version >= 5.0 and ansible_distribution == 'Ubuntu' and ansible_distribution_major_version >= '18' and 'running' not in k8sup.stdout and release == 'tegra' and container_runtime == 'containerd'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 6.0
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/nvidia-docker/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/nvidia-docker/ubuntu18.04/nvidia-docker.list
            dest: /etc/apt/sources.list.d/nvidia-docker.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.8.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 6.0 and ansible_distribution == 'Ubuntu' and ansible_distribution_major_version == '18' and 'running' not in k8sup.stdout and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 6.1
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/nvidia-docker/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/nvidia-docker/ubuntu18.04/nvidia-docker.list
            dest: /etc/apt/sources.list.d/nvidia-docker.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.9.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 6.1 and ansible_distribution == 'Ubuntu' and ansible_distribution_major_version == '18' and 'running' not in k8sup.stdout and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 6.2 or 7.0
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/nvidia-docker/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/nvidia-docker/ubuntu18.04/nvidia-docker.list
            dest: /etc/apt/sources.list.d/nvidia-docker.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.10.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 6.2 and ansible_distribution == 'Ubuntu' and 'running' not in k8sup.stdout and release == 'tegra' or cns_version == 7.0 and ansible_distribution == 'Ubuntu' and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 6.3
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu20.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.11.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 6.4 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 6.3 and ansible_distribution == 'Ubuntu' and 'running' not in k8sup.stdout and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 7.1 or 7.2 or 7.3 or 8.0 or 8.1 or 9.0 
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.11.0-1', 'nvidia-container-toolkit=1.11.0-1', 'nvidia-container-toolkit-base=1.11.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 7.1 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 8.0 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 7.2 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 8.1 and ansible_distribution == 'Ubuntu' and release == 'tegra' "

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 7.3 or 8.2 or 9.0 
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-container-runtime=3.12.0-1', 'nvidia-container-toolkit=1.12.0-1', 'nvidia-container-toolkit-base=1.12.0-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 7.3 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 8.2 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 9.0 and ansible_distribution == 'Ubuntu' and release == 'tegra' "

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 7.4 or 8.3 or 9.1 or 10.0
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Remove old Nvidia Container tooklit
          apt:
            name: ['nvidia-container-toolkit=*', 'nvidia-container-runtime*']
            state: absent
            autoremove: yes

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-docker2=2.13.0-1', 'nvidia-container-toolkit=1.13.1-1', 'nvidia-container-toolkit-base=1.13.1-1', 'libnvidia-container-tools=1.13.1-1', 'libnvidia-container1=1.13.1-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 7.4 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 8.3 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 9.1 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 10.0 and ansible_distribution == 'Ubuntu' and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 7.5 or 8.4 or 9.2 or 10.1
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Remove old nvidia container tooklit
          apt:
            name: ['nvidia-container-toolkit=*', 'nvidia-container-runtime*']
            state: absent
            autoremove: yes

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-docker2=2.13.0-1', 'nvidia-container-toolkit=1.13.2-1', 'nvidia-container-toolkit-base=1.13.2-1', 'libnvidia-container-tools=1.13.2-1', 'libnvidia-container1=1.13.2-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 7.5 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 8.4 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 9.2 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 10.1 and ansible_distribution == 'Ubuntu' and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 8.5 or 9.3 or 10.2
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Remove old nvidia container tooklit
          apt:
            name: ['nvidia-container-toolkit=*', 'nvidia-container-runtime*']
            state: absent
            autoremove: yes

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-docker2=2.13.0-1', 'nvidia-container-toolkit=1.13.5-1', 'nvidia-container-toolkit-base=1.13.5-1', 'libnvidia-container-tools=1.13.5-1', 'libnvidia-container1=1.13.5-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 8.5 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 9.3 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 10.2 and ansible_distribution == 'Ubuntu' and release == 'tegra'"

    - name: Installing Latest Nvidia Container Runtime on Cloud Native Stack 9.4 or 10.3 or 11.0
      become: true
      block:
        - name: Add NVIDIA Docker apt signing key for Ubuntu
          apt_key:
            url: https://nvidia.github.io/libnvidia-container/gpgkey
            state: present

        - name: Get NVIDIA Docker Apt list
          get_url:
            url: https://nvidia.github.io/libnvidia-container/ubuntu22.04/libnvidia-container.list
            dest: /etc/apt/sources.list.d/libnvidia-container.list
            mode: 0644

        - name: Remove old nvidia container tooklit
          apt:
            name: ['nvidia-container-toolkit=*', 'nvidia-container-runtime*']
            state: absent
            autoremove: yes

        - name: Install NVIDIA Container Runtime
          apt:
            name: ['nvidia-docker2=2.14.0-1', 'nvidia-container-toolkit=1.14.3-1', 'nvidia-container-toolkit-base=1.14.3-1', 'libnvidia-container-tools=1.14.3-1', 'libnvidia-container1=1.14.3-1']
            state: present
            update_cache: yes
            force: yes
      when: "cns_version == 9.4 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 10.3 and ansible_distribution == 'Ubuntu' and release == 'tegra' or cns_version == 11.0 and ansible_distribution == 'Ubuntu' and release == 'tegra'"

    - name: Starting and enabling the required services
      become: true
      when: "'running' not in k8sup.stdout"
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      failed_when: false
      with_items:
        - docker
        - kubelet
        - containerd
        - crio
        - cri-o
        - cri-docker

    - name: "Install Helm on NVIDIA Cloud Native Stack"
      become: true
      command: "{{ item }}"
      with_items:
        - curl -O https://get.helm.sh/helm-v{{ helm_version }}-linux-amd64.tar.gz
        - tar -xvzf helm-v{{ helm_version }}-linux-amd64.tar.gz
        - cp linux-amd64/helm /usr/local/bin/
        - rm -rf helm-v{{ helm_version }}-linux-amd64.tar.gz linux-amd64
      when: "ansible_architecture == 'x86_64'"

    - name: "Install Helm on NVIDIA Cloud Native Stack"
      become: true
      command: "{{ item }}"
      with_items:
        - curl -O https://get.helm.sh/helm-v{{ helm_version }}-linux-arm64.tar.gz
        - tar -xvzf helm-v{{ helm_version }}-linux-arm64.tar.gz
        - cp linux-arm64/helm /usr/local/bin/
        - rm -rf helm-v{{ helm_version }}-linux-arm64.tar.gz linux-arm64
      when: "ansible_architecture == 'aarch64'"